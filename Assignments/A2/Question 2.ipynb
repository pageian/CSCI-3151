{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hidden layer count\n",
      "Testing hidden layer node count\n",
      "Testing learning\n",
      "Testing max epoch\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Multi-class classifier w/ neural nets\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def graphData(X, y, xlabel):\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(X, [item[0] for item in y], 'b', label='Training Acc')\n",
    "    plt.plot(X, [item[1] for item in y], 'r', label='Validation Acc')\n",
    "    plt.title('Training Acc vs Validation Acc')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('Acc')\n",
    "    plt.legend()\n",
    "    plt.show()  \n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i,sequence in enumerate(sequences):\n",
    "        results[i,sequence] = 1\n",
    "    return results\n",
    "\n",
    "def trainModel(X_train, y_train, X_val, y_val, hidden_layers = 3, hidden_nodes = 200, learning_rate = 0.001, epochs = 20):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(10000,)))\n",
    "\n",
    "    for i in range(hidden_layers):\n",
    "        model.add(Dense(hidden_nodes, activation='relu'))\n",
    "\n",
    "    model.add(Dense(46, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    K.set_value(model.optimizer.learning_rate, learning_rate)\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=512, validation_data=(X_val, y_val), verbose = 0)\n",
    "\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "\n",
    "    return acc[-1], val_acc[-1]\n",
    "\n",
    "if \"__main__\" == __name__:\n",
    "\n",
    "    # load data\n",
    "    np_load_old = np.load\n",
    "    np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "    (X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=10000)\n",
    "    word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "    np.load = np_load_old\n",
    "\n",
    "    X_train = vectorize_sequences(X_train)\n",
    "    X_test = vectorize_sequences(X_test)\n",
    "    one_hot_y_train = to_categorical(y_train)\n",
    "    one_hot_y_test = to_categorical(y_test)\n",
    "\n",
    "    X_val = X_train[:1000]\n",
    "    partial_X_train = X_train[1000:]\n",
    "    y_val = one_hot_y_train[:1000]\n",
    "    partial_y_train = one_hot_y_train[1000:]\n",
    "\n",
    "    hidden_layer_set = range(1, 6)\n",
    "    hidden_nodes_set = [50, 100, 150, 200, 250, 300, 350]\n",
    "    learning_rate_set = [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "    epochs_set = [20, 40, 60, 80, 100]\n",
    "\n",
    "    print(\"Testing hidden layer count\")\n",
    "    hidden_layer_data = []\n",
    "    for hidden_layers in hidden_layer_set:\n",
    "        acc, acc_val = trainModel(partial_X_train, partial_y_train, X_val, y_val, hidden_layers=hidden_layers)\n",
    "        hidden_layer_data.append([acc, acc_val])\n",
    "\n",
    "    print(\"Testing hidden layer node count\")\n",
    "    hidden_nodes_data = []\n",
    "    for hidden_layer_nodes in hidden_nodes_set:\n",
    "        acc, acc_val = trainModel(partial_X_train, partial_y_train, X_val, y_val, hidden_nodes=hidden_layer_nodes)\n",
    "        hidden_nodes_data.append([acc, acc_val])\n",
    "\n",
    "    print(\"Testing learning\")\n",
    "    learning_rate_data = []\n",
    "    for learning_rate in learning_rate_set:\n",
    "        cc, acc_val = trainModel(partial_X_train, partial_y_train, X_val, y_val, learning_rate=learning_rate)\n",
    "        learning_rate_data.append([acc, acc_val])   \n",
    "\n",
    "    print(\"Testing max epoch\")\n",
    "    epochs_data =[]\n",
    "    for num_epochs in epochs_set:\n",
    "        acc, acc_val = trainModel(partial_X_train, partial_y_train, X_val, y_val, epochs=num_epochs)\n",
    "        epochs_data.append([acc, acc_val])\n",
    "\n",
    "    graphData(hidden_layer_set, hidden_layer_data, '# hidden layers')\n",
    "    graphData(hidden_nodes_set, hidden_nodes_data, '# nodes in hidden layers')\n",
    "    graphData(learning_rate_set, learning_rate_data, 'Learning rate')\n",
    "    graphData(epochs_set, epochs_data, 'epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
