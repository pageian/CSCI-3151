{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radbrad/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/radbrad/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/radbrad/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/radbrad/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/radbrad/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/radbrad/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/radbrad/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/radbrad/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/radbrad/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/radbrad/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/radbrad/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/radbrad/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/radbrad/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "### Num Nodes: 32 ###\n",
      "Test loss: 4.194984995269776 / Test accuracy: 0.03359999880194664\n",
      "### Num Nodes: 64 ###\n",
      "Test loss: 3.8485554458618165 / Test accuracy: 0.10949999839067459\n",
      "### Num Nodes: 96 ###\n",
      "Test loss: 3.645826717376709 / Test accuracy: 0.148499995470047\n",
      "### Num Nodes: 100 ###\n",
      "Test loss: 4.095536047363281 / Test accuracy: 0.07460000365972519\n",
      "### Num Nodes: 128 ###\n",
      "Test loss: 3.9920533515930177 / Test accuracy: 0.08449999988079071\n",
      "### Num Nodes: 160 ###\n",
      "Test loss: 3.9054101570129394 / Test accuracy: 0.10809999704360962\n",
      "\n",
      "Best Node Selection: 32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "if \"__main__\" == __name__:\n",
    "    # config\n",
    "    batch_size = 50\n",
    "    img_width, img_height, img_num_channels = 32, 32, 3\n",
    "    loss_function = sparse_categorical_crossentropy\n",
    "    no_classes = 100\n",
    "    no_epochs = 50\n",
    "    optimizer = Adam()\n",
    "    validation_split = 0.2\n",
    "    verbosity = 0\n",
    "\n",
    "    num_nodes = [32, 64, 96, 100, 128, 160]\n",
    "\n",
    "    # load data\n",
    "    np_load_old = np.load\n",
    "    np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "    (X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "    np.load = np_load_old\n",
    "\n",
    "    input_shape = (img_width, img_height, img_num_channels)\n",
    "\n",
    "    # Parse numbers as floats\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "\n",
    "    # Normalize data\n",
    "    X_train = X_train / 255\n",
    "    X_test = X_test / 255\n",
    "\n",
    "    num_nodes_results = []\n",
    "    for i in num_nodes:\n",
    "        # Create the model\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(i, activation='relu'))\n",
    "        model.add(Dense(i, activation='relu'))\n",
    "        model.add(Dense(no_classes, activation='softmax'))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(loss=loss_function,\n",
    "                    optimizer=optimizer,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        # Fit data to model\n",
    "        history = model.fit(X_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=1,\n",
    "                verbose=verbosity,\n",
    "                validation_split=validation_split)\n",
    "        pred = np.argmax(model.predict(X_test), axis=1)\n",
    "        \n",
    "        # Generate generalization metrics\n",
    "\n",
    "        score = model.evaluate(X_test, y_test, verbose=0)\n",
    "        num_nodes_results.append(score)\n",
    "        print(\"### Num Nodes: \" + str(i) + \" ###\")\n",
    "        print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
    "\n",
    "    best_node_num = num_nodes[num_nodes_results[1].index(max(num_nodes_results[1]))]\n",
    "    print(\"\\nBest Node Selection: \" + str(best_node_num))\n",
    "\n",
    "\n",
    "    # Find most ideal epoch\n",
    "    # Create the model\n",
    "    model_relu = Sequential()\n",
    "    model_relu.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model_relu.add(Flatten())\n",
    "    model_relu.add(Dense(best_node_num, activation='relu'))\n",
    "    model_relu.add(Dense(best_node_num, activation='relu'))\n",
    "    model_relu.add(Dense(no_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model_relu.compile(loss=loss_function,\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # Fit data to model\n",
    "    history_relu = model_relu.fit(X_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=no_epochs,\n",
    "            verbose=verbosity,\n",
    "            validation_split=validation_split)\n",
    "    pred_relu = np.argmax(model_relu.predict(X_test), axis=1)\n",
    "\n",
    "    plt.clf()\n",
    "    acc = history_relu.history['acc']\n",
    "    val_acc = history_relu.history['val_acc']\n",
    "    plt.plot(range(len(acc)), acc,'r',label='Training Accuracy')\n",
    "    plt.plot(range(len(val_acc)), val_acc, 'b', label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.clf()\n",
    "    loss = history_relu.history['loss']\n",
    "    val_loss = history_relu.history['val_loss']\n",
    "    plt.plot(range(len(loss)), loss,'y',label='Training Loss')\n",
    "    plt.plot(range(len(val_loss)), val_loss, 'g', label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    best_epoch_num = history_relu.history['val_acc'].index(max(history_relu.history['val_acc'])) + 1\n",
    "\n",
    "    # Exponential activation\n",
    "    # Use most ideal epoch\n",
    "    # Create the model\n",
    "    print(\"### Exponential ###\")\n",
    "    model_exp = Sequential()\n",
    "    model_exp.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model_exp.add(Flatten())\n",
    "    model_exp.add(Dense(best_node_num, activation='relu'))\n",
    "    model_exp.add(Dense(best_node_num, activation='relu'))\n",
    "    model_exp.add(Dense(no_classes, activation='exponential'))\n",
    "\n",
    "    # Compile the model\n",
    "    model_exp.compile(loss=loss_function,\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # Fit data to model\n",
    "    history_exp = model_exp.fit(X_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=best_epoch_num,\n",
    "            verbose=verbosity,\n",
    "            validation_split=validation_split)\n",
    "    pred_exp = np.argmax(model_exp.predict(X_test), axis=1)\n",
    "\n",
    "\n",
    "    # Sigmoid activation\n",
    "    # Use most ideal epoch\n",
    "    # Create the model\n",
    "    print(\"### Sigmoid ###\")\n",
    "    model_sigmoid = Sequential()\n",
    "    model_sigmoid.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model_sigmoid.add(Flatten())\n",
    "    model_sigmoid.add(Dense(best_node_num, activation='relu'))\n",
    "    model_sigmoid.add(Dense(best_node_num, activation='relu'))\n",
    "    model_sigmoid.add(Dense(no_classes, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model_sigmoid.compile(loss=loss_function,\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # Fit data to model\n",
    "    history_sigmoid = model_sigmoid.fit(X_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=best_epoch_num,\n",
    "            verbose=verbosity,\n",
    "            validation_split=validation_split)\n",
    "    pred_sigmoid = np.argmax(model_sigmoid.predict(X_test), axis=1)\n",
    "\n",
    "    plt.clf()\n",
    "    relu_acc = history_relu.history['val_acc']\n",
    "    exp_acc = history_exp.history['val_acc']\n",
    "    sigmoid_acc = history_sigmoid.history['val_acc']\n",
    "    plt.plot(range(len(relu_acc)), relu_acc,'r',label='Relu')\n",
    "    plt.plot(range(len(exp_acc)), exp_acc, 'b', label='Exponential')\n",
    "    plt.plot(range(len(sigmoid_acc)), sigmoid_acc, 'g', label='Sigmoid')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Val. Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    max_relu_acc = max(history_relu.history['val_acc'])\n",
    "    max_exp_acc = max(history_exp.history['val_acc'])\n",
    "    max_sigmoid_acc = max(history_sigmoid.history['val_acc'])\n",
    "\n",
    "    fin_pred = []\n",
    "    if(max_relu_acc >= max_exp_acc and max_relu_acc >= max_sigmoid_acc):\n",
    "            fin_pred = pred_relu   \n",
    "    elif(max_exp_acc >= max_relu_acc and max_exp_acc >= max_sigmoid_acc):\n",
    "            fin_pred = pred_exp  \n",
    "    else:\n",
    "            fin_pred = pred_sigmoid \n",
    "\n",
    "    cm = confusion_matrix(y_test, fin_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    class_acc = cm.diagonal()\n",
    "\n",
    "    max_acc = class_acc.argmax(axis=0)\n",
    "    min_acc = class_acc.argmin(axis=0)\n",
    "    print(\"Max Accuracy class #: \" + str(max_acc) + \" - \" + str(class_acc[max_acc]))\n",
    "    print(\"Min Accuracy class #: \" + str(min_acc) + \" - \" + str(class_acc[min_acc]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
